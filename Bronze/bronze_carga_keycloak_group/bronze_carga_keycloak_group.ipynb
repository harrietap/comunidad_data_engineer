{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffab97d3-12e9-4879-b163-bdcd1d8c6489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#keycloak_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a969c9-07f3-4b5a-a789-b84df48a18ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Configuración de conexión JDBC\n",
    "JDBC_CONFIG = {\n",
    "    \"hostname\": \"psql-dn-keycloak-restore-2.postgres.database.azure.com\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"keycloak\",\n",
    "    \"username\": dbutils.secrets.get(scope='secret-storeview', key='username-keycloak-db'),\n",
    "    \"password\": dbutils.secrets.get(scope='secret-storeview', key='password-keycloak-db'),\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "jdbcUrl = f\"jdbc:postgresql://{JDBC_CONFIG['hostname']}:{JDBC_CONFIG['port']}/{JDBC_CONFIG['database']}?sslmode=require\"\n",
    "connectionProperties = {\n",
    "    \"user\": JDBC_CONFIG[\"username\"],\n",
    "    \"password\": JDBC_CONFIG[\"password\"],\n",
    "    \"driver\": JDBC_CONFIG[\"driver\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7982a9ba-acbd-4762-91a7-5961c777e119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#consultar tablas\n",
    "\n",
    "df_tablas = spark.read.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"keycloak_group\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "# Mostrar los nombres de las tablas\n",
    "df_tablas.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c489295-0d0d-4aab-bcf5-d170d1ebefcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se importa los tipos de datos necesarios para definir el esquema del DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Controlar los tipos de datos y evitar inferencias automáticas de Spark\n",
    "schema_keycloak_group = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"parent_group\", StringType(), True),\n",
    "    StructField(\"realm_id\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "363b73d1-2ce3-4dfc-9603-eeb50bf1bde5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Leer la tabla \"keycloak_group\" desde PostgreSQL usando el esquema definido\n",
    "# Para garantizar que los tipos de datos sean los correctos\n",
    "df_keycloak_group = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbcUrl) \\\n",
    "    .option(\"dbtable\", \"keycloak_group\") \\\n",
    "    .option(\"user\", connectionProperties[\"user\"]) \\\n",
    "    .option(\"password\", connectionProperties[\"password\"]) \\\n",
    "    .option(\"driver\", connectionProperties[\"driver\"]) \\\n",
    "    .schema(schema_keycloak_group)\\\n",
    "    .load()\n",
    "\n",
    "# Mostrar los primeros 10 registros para verificar la lectura\n",
    "display(df_keycloak_group.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e1b0f9a-1071-46ed-8dbc-a1d4a9141789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Validar el esquema\n",
    "def validar_esquema_postgresql(jdbc_url, table_name, connection_props, schema_keycloak_group):\n",
    "\n",
    "    # Leer la tabla desde PostgreSQL usando el esquema definido\n",
    "    df_actual = spark.read.jdbc(url=jdbc_url, table=table_name, properties=connection_props)\n",
    "    actual_schema = df_actual.schema\n",
    "\n",
    "    # Comparar los esquemas\n",
    "    expected_fields = {field.name: type(field.dataType) for field in schema_keycloak_group.fields}\n",
    "    actual_fields = {field.name: type(field.dataType) for field in actual_schema.fields}\n",
    "\n",
    "    errores = False # Variable para controlar si hay errores\n",
    "\n",
    "    #Revisar si hay colummnas faltantes o con tipos diferentes\n",
    "    for col in expected_fields:\n",
    "        if col not in actual_fields:\n",
    "            print(f\"⚠️ Columna faltante: '{col}'\")\n",
    "            errores = True\n",
    "        elif expected_fields[col] != actual_fields[col]:\n",
    "            print(f\"⚠️ Tipo cambiado en '{col}': esperado {expected_fields[col]}, recibido {actual_fields[col]}\")\n",
    "            errores = True\n",
    "\n",
    "    #Revisar si hay columnas adicionales\n",
    "    for col in actual_fields:\n",
    "        if col not in expected_fields:\n",
    "            print(f\"⚠️ Columna adicional no esperada: '{col}'\")\n",
    "            errores = True\n",
    "\n",
    "    # Mostrar el resdultado de si hubo o no errores\n",
    "    if errores:\n",
    "        print(\"❌ El esquema actual NO coincide con el esperado.\")\n",
    "    else:\n",
    "        print(\"✅ El esquema actual coincide con el esperado.\")\n",
    "\n",
    "        # Mostrar los primeros 10 registros para verificar la lectura\n",
    "        display(df_actual.limit(10))\n",
    "\n",
    "# Ejecutar la validación\n",
    "validar_esquema_postgresql(jdbcUrl, \"keycloak_group\", connectionProperties, schema_keycloak_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0013903-55ae-4963-b1fc-8ecda275ea8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ruta destino en Bronze\n",
    "bronze_path = \"/mnt/bronze/keycloak/dn_keycloak_group\"\n",
    "\n",
    "# Eliminar en caso que exista\n",
    "try:\n",
    "  dbutils.fs.ls(bronze_path)\n",
    "  print(\"Existe, se sobreescribirá\")\n",
    "except:\n",
    "  print(\"No existe, se creará\")\n",
    "\n",
    "# Escribir en delta\n",
    "df_keycloak_group.write.format(\"delta\").mode(\"overwrite\").save(bronze_path)\n",
    "\n",
    "# Registrar tabla\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bronze.dn_keycloak_group\n",
    "    USING DELTA\n",
    "    LOCATION '{bronze_path}/'\n",
    "\"\"\")\n",
    "spark.sql(\"REFRESH TABLE bronze.dn_keycloak_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce3bfb7-a038-48d3-a014-36e261455923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# consultar tabla\n",
    "spark.sql(\"SELECT * FROM bronze.dn_keycloak_group\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "363a2f66-a081-4531-ab80-627ea548cd98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE bronze.dn_keycloak_group\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4970882964299067,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_carga_keycloak_group",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
